% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/model_estimate.R
\name{model_estimate}
\alias{model_estimate}
\title{Model estimation}
\usage{
model_estimate(
  X,
  M,
  Y,
  I_update,
  X.scale = TRUE,
  tol = 10^(-10),
  max.iter = 10,
  lambda1 = exp(seq(1, -3, length = 10)),
  lambda2 = exp(-1),
  alpha = 1,
  penalty.factor = c(1, rep(1, ncol(M) * 2), rep(1, max(0, ncol(I_update)))),
  verbose = FALSE,
  Omega.out = FALSE,
  non.zeros.stop = ncol(M)
)
}
\arguments{
\item{X}{one-dimensional exposure}

\item{M}{multivariate mediators}

\item{Y}{one-dimensional outcome}

\item{I_update}{interaction term}

\item{X.scale}{whether scale X (default = \code{TRUE})}

\item{tol}{convergence criterion (default = -10^(-10))}

\item{max.iter}{maximum iteration (default = 100)}

\item{lambda1}{tuning parameter for regression coefficient L1 penalization}

\item{lambda2}{tuning parameter for covariance matrix}

\item{alpha}{alpha in glmnet() (default = 1: lasso penalty)}

\item{penalty.factor}{penalty factor vector, in the order of (c,b1,b2,a)}

\item{verbose}{print progress (default = \code{TRUE})}

\item{Omega.out}{output Omega estimates (default = \code{FALSE})}

\item{non.zeros.stop}{when to stop the regularization path (default = ncol(M))}
}
\value{
c: direct effect estimate

hatb1: path b1 (M->Y given X) estimates

hatb2: path b2 (X*M->Y) estimates

hata: path a (X->M) estimates

nump: number of selected paths + 1 direct effect

Omega: estimated covariance matrix of the mediators

sigmasq: estimated variance of the outcome
}
\description{
This function gives the model estimates.
}
\examples{
data = dat_gen(200,100,es = 1)
X = data$X; Y = data$Y; M = data$M; I = X*M
model_estimate(X, M, Y, I, lambda1 = 0.2, lambda2 = 0.1, alpha = 1, Omega.out = F)
}
